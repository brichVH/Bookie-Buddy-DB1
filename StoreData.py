# -*- coding: utf-8 -*-
"""bookie-buddy-sentiment-analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hASG-b3ONtf1l_UUFaV4DavUWUN349G9
"""

# description - this is a sentiment analysis program that parses the tweets fetched from twitter using python

# import libraries
import tweepy
from textblob import TextBlob
from azure.storage.blob import BlobServiceClient
import pandas as pd
import numpy as np
import re
from datetime import datetime

# azure blob storage api credentials
storage_account_key = ""
storage_account_name = "blakestorageaccount581"
connection_string = ""
container_name = "csv-files"

# upload to blob storage function
def uploadToBlobStorage(file_path, file_name):
  blob_service_client = BlobServiceClient.from_connection_string(connection_string)
  blob_client = blob_service_client.get_blob_client(container=container_name, blob=file_name)

  with open(file_path, "rb") as data:
    blob_client.upload_blob(data)
  print(f"uploaded {file_name}")

# Get Twitter API credentials
# log = pd.read_excel(io='Login2.xlsx')

# Twitter API Credentials
consumerKey = 'sqgapvVGFD7pDpk7r9VBQY3Gx'
consumerSecret = 'bAOV0hCsMTSSOKdISa4xfwKyM6omezhpzeRcS8U6Khv4DBPGCh'
accessToken = '1925363064-cmumL8gkh0X9MT4eTaZSu0gNEJCodUZSJRR8LKJ'
accessTokenSecret = 'AKXWEjczoyyGih0D3TzEwXZcvfbWsHsKErkkXKVRBwIlC'

# create the authentication object
authenticate = tweepy.OAuthHandler(consumerKey, consumerSecret)

authenticate.set_access_token(accessToken, accessTokenSecret )

# Create the API opject while passing in the auth info
api = tweepy.API(authenticate, wait_on_rate_limit = True)

# Extract 100 tweets from the twitter user
posts = api.user_timeline(screen_name = "GottliebShow", count = 500, tweet_mode="extended")
posts += api.user_timeline(screen_name = "ClubTrillion", count = 500, tweet_mode="extended")
posts += api.user_timeline(screen_name = "jerrymeyer247", count = 500, tweet_mode="extended")
posts += api.user_timeline(screen_name = "JohnGasaway", count = 500, tweet_mode="extended")
posts += api.user_timeline(screen_name = "GaryParrishCBS", count = 500, tweet_mode="extended")
posts += api.user_timeline(screen_name = "JayBilas", count = 500, tweet_mode="extended")
posts += api.user_timeline(screen_name = "ESPNLunardi", count = 500, tweet_mode="extended")
posts += api.user_timeline(screen_name = "RobDauster", count = 500, tweet_mode="extended")
posts += api.user_timeline(screen_name = "JonRothstein", count = 500, tweet_mode="extended")
posts += api.user_timeline(screen_name = "eamonnbrennan", count = 500, tweet_mode="extended")
posts += api.user_timeline(screen_name = "kenpomeroy", count = 500, tweet_mode="extended")
posts += api.user_timeline(screen_name = "SethDavisHoops", count = 500, tweet_mode="extended")
posts += api.user_timeline(screen_name = "HeatCheckCBB", count = 500, tweet_mode="extended")
posts += api.user_timeline(screen_name = "HeatCheckCBB", count = 500, tweet_mode="extended")
posts += api.user_timeline(screen_name = "TheAndyKatz", count = 500, tweet_mode="extended")
posts += api.user_timeline(screen_name = "evanmiya", count = 500, tweet_mode="extended")
posts += api.user_timeline(screen_name = "32_Analytics", count = 500, tweet_mode="extended")
posts += api.user_timeline(screen_name = "AdamFinkelstein", count = 500, tweet_mode="extended")
posts += api.user_timeline(screen_name = "SethOnHoops", count = 500, tweet_mode="extended")
posts += api.user_timeline(screen_name = "wallyball", count = 500, tweet_mode="extended")
posts += api.user_timeline(screen_name = "CWalkerSports", count = 500, tweet_mode="extended")

#create dataframe with column called tweets
df = pd.DataFrame( [tweet.full_text for tweet in posts], columns=['Tweets'])
df['ID_str'] = [str(tweet.id) for tweet in posts]
df['create_time'] = [str(tweet.created_at) for tweet in posts]
#show the first five rows of data
print(df.head())

# clean the text 
def cleanText(text):
  text = re.sub(r'@[A-Za-z0-9]+', '', text)
  text = re.sub(r'#', '', text)
  text = re.sub(r'RT[\s]+', '', text)
  text = re.sub(r'https?:\/\/\S+', '', text)
  emoji_pattern = re.compile("["
        u"\U0001F600-\U0001F64F"  # emoticons
        u"\U0001F300-\U0001F5FF"  # symbols & pictographs
        u"\U0001F680-\U0001F6FF"  # transport & map symbols
        u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                           "]+", flags=re.UNICODE)
  text = emoji_pattern.sub(r'', text) # no emoji
  return text

df['Tweets'] = df['Tweets'].apply(lambda x: x.replace('\'', ''))
df['Tweets'] = df['Tweets'].apply(lambda x: x.replace(',', ''))
df['Tweets'] = df['Tweets'].apply(lambda x: x.replace('â€™', ''))
df['Tweets'] = df['Tweets'].apply(cleanText)
df['Tweets'] = df['Tweets'].str.lower()
df['Tweets'] = df['Tweets'].apply(lambda x: x.replace('kansas state ', 'kansas_state'))
df['Tweets'] = df['Tweets'].apply(lambda x: x.replace('iowa state', 'iowa_state'))
df['Tweets'] = df['Tweets'].apply(lambda x: x.replace('oklahoma state', 'oklahoma_state'))
df['Tweets'] = df['Tweets'].apply(lambda x: x.replace('texas tech', 'texas_tech'))
df['Tweets'] = df['Tweets'].apply(lambda x: x.replace('michigan state', 'michigan_state'))
df['Tweets'] = df['Tweets'].apply(lambda x: x.replace('north carolina state', 'north_carolina_state'))
df['Tweets'] = df['Tweets'].apply(lambda x: x.replace('texas tech', 'texas_tech'))
df['Tweets'] = df['Tweets'].apply(lambda x: x.replace('virginia tech', 'virginia_tech'))
df['Tweets'] = df['Tweets'].apply(lambda x: x.replace('georgia tech', 'georgia_tech'))
df['Tweets'] = df['Tweets'].apply(lambda x: x.replace('arizona state', 'arizona_state'))
df['Tweets'] = df['Tweets'].apply(lambda x: x.replace('oregon state', 'oregon_state'))
df['Tweets'] = df['Tweets'].apply(lambda x: x.replace('washington state', 'washington_state'))
df['Tweets'] = df['Tweets'].apply(lambda x: x.replace('mississippi state', 'mississippi_state'))
df['Tweets'] = df['Tweets'].apply(lambda x: x.replace('texas a&m', 'texas_a&m'))
df['Tweets'] = df['Tweets'].apply(lambda x: x.replace('san diego state', 'san_diego_state'))
df['Tweets'] = df['Tweets'].apply(lambda x: x.replace('florida atlantic', 'florida_atlantic'))

# show clean text

#subjectivity and polarity
def getSubjectivity(text):
  return round(TextBlob(text).sentiment.subjectivity, 4)

def getPolarity(text):
  return round(TextBlob(text).sentiment.polarity, 4)

df['Subjectivity'] = df['Tweets'].apply(getSubjectivity)
df['Polarity'] = df['Tweets'].apply(getPolarity)

df

#create a function to compute negative positive and neutral analysis
def GetAnalysis(score): 
  if score < 0:
    return 'Negative'
  elif score == 0:
    return 'Neutral'
  else:
    return 'Positive'

df['Analysis'] = df['Polarity'].apply(GetAnalysis)

j=1

sortedDF = df.sort_values(by=['Polarity'])

for i in range(0, sortedDF.shape[0]):
  if (sortedDF['Analysis'][i] == 'Positive'): 
    # print(str(j) + ") " + sortedDF['Tweets'][i])
    j+=1

j=1
sortedDF = df.sort_values(by=['Polarity'], ascending = False)

ptweets = df[df.Analysis=='Positive']
ptweets = ptweets['Tweets']

round ( (ptweets.shape[0] / df.shape[0])*100, 1)

# percentage of negative tweets
ptweets = df[df.Analysis=='Negative']
ptweets = ptweets['Tweets']

round ( (ptweets.shape[0] / df.shape[0])*100, 1)

teams = {
    # BIG 12
    "kansas_state" : ['k-state', 'k state', 'wildcats', 'kansas state','kansas_state'], #
    "kansas" : ['kansas ', 'jayhawks'],
    "baylor" : ['baylor', 'baylor'],
    "iowa_state" : ['iowa state', 'cyclones', 'iowa_state'], #
    "oklahoma" : ['oklahoma ', 'sooners'], 
    "oklahoma_state" : ['oklahoma state', 'cowboys', 'oklahoma_state'], #
    "texas_christian" : ['tcu', 'horned frogs'],
    "texas" : ['texas ', 'longhorns'],
    "texas_tech" : ['texas tech', 'red raiders', 'texas_tech', 'texas_tech'], #
    "west_virginia" : ['west virginia', 'mountaineers'],
    # BIG 10
    "illinois" : ["illinois", "illini"],
    "michigan_state" : ["michigan state", "spartans", 'michigan_state'], #
    "wisconsin" : ["wisconsin", "badgers"],
    "minnesota" : ["minnesota", "gophers", "golden gophers"],
    "iowa" : ["iowa ", "hawkeyes"],
    "ohio_state" : ["ohio state", "buckeyes"],
    "purdue" : ["purdue", "boilermakers"],
    "michigan" : ["michigan ", "wolverines"],
    "penn_state" : ["penn state", "nittany lions"],
    "nebraska" : ["nebraska", "huskers", "cornhuskers", "big red"],
    "indiana" : ["hoosiers", "indiana "],
    "maryland" : ["maryland", "terrapins"],
    "rutgers" : ["rutgers", "scarlet knights"],
    # ACC
    "north_carolina": ["north carolina ", "tar heels"],
    "clemson" : ["clemson", "tigers"],
    "florida_state" : ["florida state", "seminoles"],
    "syracuse" : ["syracuse", "orange"],
    "north_carolina_state" : ["nc state", "north carolina state", "wolfpack", "wolf pack", 'north_carolina_state'], # 
    "miami" : ["miami", "hurricanes", "canes"],
    "virginia" : ["virginia", "cavaliers", "cavs"],
    "pittsburgh" : ["pitt", "pittsburgh", "panthers"], 
    "virginia_tech" : ["virginia tech", "hokies", 'virginia_tech'], #
    "duke" : ["duke", "blue devils"],
    "wake_forest" : ["wake forest", "demon deacons"],
    "georgia_tech" : ["georgia tech", "yellow jackets", 'georgia_tech'], #
    "louisville" : ["louisville", "cardinals"],
    "boston_college" : ["boston college", "eagles"],
    # PAC12
    "arizona" : ["arizona ", "wildcats"],
    "arizona_state" : ["arizona state", "sun devils", 'arizona_state'], #
    "california" : ["cal", "california", "bears", "golden bears", "cal berkeley", "uc berkeley"],
    "ucla" : ["ucla", "bruins"],
    "colorado" : ["boulder", "colorado ", "buffalos", "buffs"],
    "oregon" : ["oregon ", "ducks"],
    "oregon_state" : ["oregon state", "beavers", 'oregon_state'], #
    "usc" : ["usc", "southern california", "trojans"],
    "stanford" : ["stanford", "cardinals"],
    "utah" : ["utah ", "utes"],
    "washington" : ["wahsington ", "huskies"],
    "washington_state" : ["washington state", "cougars", 'washington_state'], #
    # SEC
    "auburn" : ["auburn", "tigers"],
    "louisiana_state" : ["lsu", "louisiana state", "tigers"],
    "mississippi_state" : ["mississippa state", "bulldogs", 'mississippi_state'], #
    "texas_am" : ["texas a&m", "aggies", 'texas_a&m'], #
    "alabama" : ["alabama", "bama", "tide", "crimson tide"],
    "arkansas" : ["arkansas", "razorbacks"],
    "florida" : ["florida ", "gators"],
    "georgia" : ["georgia ", "bulldogs"],
    "kentucky" : ["kentucky", "wildcats"],
    "mississippi" : ["mississippi ", "ole miss", "rebels"],
    "missouri" : ["missouri", "tigers", "mizzou"],
    "south_carolina" : ["south carolina", "gamecocks", "cocks"],
    "tennessee" : ["tennessee", "volunteers", "vols"],
    "vanderbilt" : ["vanderbilt", "commodores", "vandy"],
    # EXTRA
    "san_diego_state" : ["san diego state", "sdsu", "aztecs", "san_diego_state"],
    "creighton" : ["blue jays", "creighton", "jays"],
    "xavier" : ["xavier", "musketeers"],
    "princeton" : ["princeton"],
    "houston" : ["cougars", "cougar", "houston"],
    "florida_atlantic" : ["fau", "florida atlantic", "owl", "florida_atlantic"],
    "gonzaga" : ["zags", "gonzaga"],
    "connecticut" : ["connecticut", "uconn", "huskies"]
}

def sortWordsBool(word):
    df[word] = np.where(df['Tweets'].str.contains('|'.join(teams[word])),1,0)

x = list(map(sortWordsBool, teams))

curr = datetime.now()
filename = 'data_' + curr.strftime('%b-%d-%Y_%H-%M-%S') + '.csv'
print(filename)

df.to_csv(filename, index=False)

uploadToBlobStorage(filename , filename)
